{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T08:00:32.002163816Z",
     "start_time": "2023-09-25T08:00:31.986949398Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python c:\\Users\\ACERPC\\Desktop\\robosuite\\robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    }
   ],
   "source": [
    "import robosuite as suite\n",
    "from robosuite.wrappers.gym_wrapper import GymWrapper\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cac3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "new_folder = os.path.join(cwd, \"tmp/gym\")\n",
    "os.makedirs(new_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f26bfc569a1dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T06:25:12.970212130Z",
     "start_time": "2023-09-25T06:25:11.779955106Z"
    }
   },
   "outputs": [],
   "source": [
    "# create environment instance\n",
    "env = GymWrapper(suite.make(\n",
    "    env_name=\"Lift\", # try with other tasks like \"Stack\" and \"Door\"\n",
    "    robots=\"UR5e\",  # try with other robots like \"Sawyer\" and \"Jaco\"\n",
    "    has_renderer=True,\n",
    "    has_offscreen_renderer=True,\n",
    "    use_object_obs=True,                   # don't provide object observations to agent\n",
    "    use_camera_obs=True,\n",
    "    camera_names=\"robot0_eye_in_hand\",      # use \"agentview\" camera for observations\n",
    "    camera_heights=84,                      # image height\n",
    "    camera_widths=84,                       # image width\n",
    "    reward_shaping=True,                    # use a dense reward signal for learning\n",
    "    horizon = 500\n",
    "    control_freq=20,                        # control should happen fast enough so that simulation looks smooth\n",
    "))\n",
    "env = Monitor(env, \"tmp/gym\" )\n",
    "# ), ['robot0_eye_in_hand_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe79fc835d0d5d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T06:48:04.884357Z",
     "start_time": "2023-09-25T06:27:32.303421583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b01ac934ee940c386737853d3b5e300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x21413954610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=2048, progress_bar=True, log_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650999e57ee19c05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T08:01:01.175729695Z",
     "start_time": "2023-09-25T08:00:36.924182236Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ACERPC\\Desktop\\robosuite\\rb_custom.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ACERPC/Desktop/robosuite/rb_custom.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m action, state \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ACERPC/Desktop/robosuite/rb_custom.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m obs, reward, done,done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ACERPC/Desktop/robosuite/rb_custom.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m env\u001b[39m.\u001b[39;49mrender()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ACERPC/Desktop/robosuite/rb_custom.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m0.2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ACERPC/Desktop/robosuite/rb_custom.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[1;32mc:\\Users\\ACERPC\\anaconda3\\envs\\robo_custom\\lib\\site-packages\\gymnasium\\core.py:471\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RenderFrame \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[RenderFrame] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[1;32mc:\\Users\\ACERPC\\Desktop\\robosuite\\robosuite\\wrappers\\wrapper.py:71\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     65\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39m    By default, run the normal environment render() function\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39m        **kwargs (dict): Any args to pass to environment render function\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ACERPC\\Desktop\\robosuite\\robosuite\\environments\\base.py:450\u001b[0m, in \u001b[0;36mMujocoEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    447\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[39m    Renders to an on-screen window.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mviewer\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[1;32mc:\\Users\\ACERPC\\Desktop\\robosuite\\robosuite\\utils\\opencv_renderer.py:29\u001b[0m, in \u001b[0;36mOpenCVRenderer.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     28\u001b[0m     \u001b[39m# get frame with offscreen renderer (assumes that the renderer already exists)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     im \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msim\u001b[39m.\u001b[39;49mrender(camera_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcamera_name, height\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheight, width\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwidth)[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, ::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     31\u001b[0m     \u001b[39m# write frame to window\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     im \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mflip(im, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ACERPC\\Desktop\\robosuite\\robosuite\\utils\\binding_utils.py:1133\u001b[0m, in \u001b[0;36mMjSim.render\u001b[1;34m(self, width, height, camera_name, depth, mode, device_id, segmentation)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39mwith\u001b[39;00m _MjSim_render_lock:\n\u001b[0;32m   1130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_render_context_offscreen\u001b[39m.\u001b[39mrender(\n\u001b[0;32m   1131\u001b[0m         width\u001b[39m=\u001b[39mwidth, height\u001b[39m=\u001b[39mheight, camera_id\u001b[39m=\u001b[39mcamera_id, segmentation\u001b[39m=\u001b[39msegmentation\n\u001b[0;32m   1132\u001b[0m     )\n\u001b[1;32m-> 1133\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render_context_offscreen\u001b[39m.\u001b[39;49mread_pixels(width, height, depth\u001b[39m=\u001b[39;49mdepth, segmentation\u001b[39m=\u001b[39;49msegmentation)\n",
      "File \u001b[1;32mc:\\Users\\ACERPC\\Desktop\\robosuite\\robosuite\\utils\\binding_utils.py:173\u001b[0m, in \u001b[0;36mMjRenderContext.read_pixels\u001b[1;34m(self, width, height, depth, segmentation)\u001b[0m\n\u001b[0;32m    170\u001b[0m rgb_img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((height, width, \u001b[39m3\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\n\u001b[0;32m    171\u001b[0m depth_img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((height, width), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32) \u001b[39mif\u001b[39;00m depth \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m mujoco\u001b[39m.\u001b[39;49mmjr_readPixels(rgb\u001b[39m=\u001b[39;49mrgb_img, depth\u001b[39m=\u001b[39;49mdepth_img, viewport\u001b[39m=\u001b[39;49mviewport, con\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcon)\n\u001b[0;32m    175\u001b[0m ret_img \u001b[39m=\u001b[39m rgb_img\n\u001b[0;32m    176\u001b[0m \u001b[39mif\u001b[39;00m segmentation:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obs = env.reset()[0]\n",
    "for i in range(500):\n",
    "    action, state = model.predict(obs)\n",
    "    obs, reward, done,done, info = env.step(action)\n",
    "    env.render()\n",
    "    time.sleep(0.2)\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6e88f34c3e1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T07:45:52.507218709Z",
     "start_time": "2023-09-25T07:19:44.084127030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0d0b5f52c94a4a92ccf9d336e32bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 500        |\n",
      "|    ep_rew_mean          | 74.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 89         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 227        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49315557 |\n",
      "|    clip_fraction        | 0.723      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.56      |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0686    |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | -0.0664    |\n",
      "|    std                  | 0.401      |\n",
      "|    value_loss           | 0.785      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 500       |\n",
      "|    ep_rew_mean          | 80.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 88        |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 460       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6722676 |\n",
      "|    clip_fraction        | 0.759     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.91     |\n",
      "|    explained_variance   | 0.875     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.107    |\n",
      "|    n_updates            | 1660      |\n",
      "|    policy_gradient_loss | -0.0735   |\n",
      "|    std                  | 0.365     |\n",
      "|    value_loss           | 0.442     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 500       |\n",
      "|    ep_rew_mean          | 90.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 88        |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 697       |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7316275 |\n",
      "|    clip_fraction        | 0.781     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.33     |\n",
      "|    explained_variance   | 0.921     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0569   |\n",
      "|    n_updates            | 1760      |\n",
      "|    policy_gradient_loss | -0.0568   |\n",
      "|    std                  | 0.337     |\n",
      "|    value_loss           | 0.464     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 500       |\n",
      "|    ep_rew_mean          | 91        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 88        |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 930       |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0585983 |\n",
      "|    clip_fraction        | 0.762     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.77     |\n",
      "|    explained_variance   | 0.965     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0505   |\n",
      "|    n_updates            | 1860      |\n",
      "|    policy_gradient_loss | -0.0706   |\n",
      "|    std                  | 0.311     |\n",
      "|    value_loss           | 0.372     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "model = PPO.load('trained_model', env=env)\n",
    "model.learn(total_timesteps=100000, progress_bar=True, log_interval=10)\n",
    "model.save('trained_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e997e532ad5e1641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32703687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
